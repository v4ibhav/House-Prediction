{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain = pd.read_csv(\"Train_Data.csv\")\n",
    "XTest = pd.read_csv(\"Test_Data.csv\")\n",
    "XTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain =XTrain.fillna(0)\n",
    "XTest = XTest.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 80)\n"
     ]
    }
   ],
   "source": [
    "print(XTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = XTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = XTrain\n",
    "# print(dataset)\n",
    "Dataset = XTrain.drop('SalePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 80)\n"
     ]
    }
   ],
   "source": [
    "print(Dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 80)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset.drop('SalePrice',axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target =dataset['SalePrice']\n",
    "target = pd.DataFrame(target)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_objs_num = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0)\n",
    "dataset_preprocessed = pd.get_dummies(dataset)\n",
    "train = dataset_preprocessed[:train_objs_num]\n",
    "test = dataset_preprocessed[train_objs_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 305)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 305)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Scalar.fit_transform(train)\n",
    "test = Scalar.fit_transform(test)\n",
    "target = Scalar.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 305)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(train,target,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 305)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# train_test_split()\n",
    "# Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13623108],\n",
       "       [0.25913068],\n",
       "       [0.03624497],\n",
       "       [0.36786557],\n",
       "       [0.09908346],\n",
       "       [0.20705458],\n",
       "       [0.50033606],\n",
       "       [0.38897375],\n",
       "       [0.20594362],\n",
       "       [0.17789196],\n",
       "       [0.11123455],\n",
       "       [0.11887238],\n",
       "       [0.29718095],\n",
       "       [0.09425913],\n",
       "       [0.14456326],\n",
       "       [0.09040411],\n",
       "       [0.17094848],\n",
       "       [0.13900847],\n",
       "       [0.14456326],\n",
       "       [0.22024719],\n",
       "       [0.12859325],\n",
       "       [0.03485627],\n",
       "       [0.11540064],\n",
       "       [0.13900847],\n",
       "       [0.40424941],\n",
       "       [0.38064158],\n",
       "       [0.13137064],\n",
       "       [0.16525483],\n",
       "       [0.32925983],\n",
       "       [0.09484794],\n",
       "       [0.1653937 ],\n",
       "       [0.40827663],\n",
       "       [0.41674767],\n",
       "       [0.39591723],\n",
       "       [0.26399111],\n",
       "       [0.07790585],\n",
       "       [0.11123455],\n",
       "       [0.28898764],\n",
       "       [0.11803916],\n",
       "       [0.13900847],\n",
       "       [0.14039717],\n",
       "       [0.06401889],\n",
       "       [0.11123455],\n",
       "       [0.30551312],\n",
       "       [0.25635328],\n",
       "       [0.15845022],\n",
       "       [0.14734065],\n",
       "       [0.19247327],\n",
       "       [0.21538675],\n",
       "       [0.15983891],\n",
       "       [0.1653937 ],\n",
       "       [0.14178586],\n",
       "       [0.21885849],\n",
       "       [0.14734065],\n",
       "       [0.07651715],\n",
       "       [0.27162894],\n",
       "       [0.18066935],\n",
       "       [0.40147202],\n",
       "       [0.30242744],\n",
       "       [0.33342591],\n",
       "       [0.31259547],\n",
       "       [0.06540758],\n",
       "       [0.11262325],\n",
       "       [0.50006943],\n",
       "       [0.12512151],\n",
       "       [0.14595195],\n",
       "       [0.19316762],\n",
       "       [0.40286071],\n",
       "       [0.0694348 ],\n",
       "       [0.22913484],\n",
       "       [0.18552979],\n",
       "       [0.19927788],\n",
       "       [0.17233718],\n",
       "       [0.21538675],\n",
       "       [0.27093459],\n",
       "       [0.20844327],\n",
       "       [0.28343286],\n",
       "       [0.15567282],\n",
       "       [0.15706152],\n",
       "       [0.33412026],\n",
       "       [0.39322455],\n",
       "       [0.10359672],\n",
       "       [0.39591723],\n",
       "       [0.13067629],\n",
       "       [0.49928066],\n",
       "       [0.18053048],\n",
       "       [0.08554367],\n",
       "       [0.31736564],\n",
       "       [0.20844327],\n",
       "       [0.13067629],\n",
       "       [0.11331759],\n",
       "       [0.11123455],\n",
       "       [0.10429107],\n",
       "       [0.56086655],\n",
       "       [0.14588252],\n",
       "       [0.21191501],\n",
       "       [0.2096931 ],\n",
       "       [0.11609499],\n",
       "       [0.23274545],\n",
       "       [0.16817109],\n",
       "       [0.22371893],\n",
       "       [0.37092071],\n",
       "       [0.12998195],\n",
       "       [0.13484238],\n",
       "       [0.15358978],\n",
       "       [0.10429107],\n",
       "       [0.25843633],\n",
       "       [0.2663519 ],\n",
       "       [0.19594501],\n",
       "       [0.57915567],\n",
       "       [0.14109152],\n",
       "       [0.25010415],\n",
       "       [0.21677545],\n",
       "       [0.31833356],\n",
       "       [0.16678239],\n",
       "       [0.21191501],\n",
       "       [0.11262325],\n",
       "       [0.11678933],\n",
       "       [0.10845716],\n",
       "       [0.13824469],\n",
       "       [0.12998195],\n",
       "       [0.18761283],\n",
       "       [0.14428552],\n",
       "       [0.43480072],\n",
       "       [0.06957367],\n",
       "       [0.11540064],\n",
       "       [0.39001528],\n",
       "       [0.27542008],\n",
       "       [0.08762672],\n",
       "       [0.07860019],\n",
       "       [0.54311901],\n",
       "       [0.16817109],\n",
       "       [0.31467852],\n",
       "       [0.10012498],\n",
       "       [0.22927371],\n",
       "       [0.16122761],\n",
       "       [0.14595195],\n",
       "       [0.1987224 ],\n",
       "       [0.12442716],\n",
       "       [0.11817803],\n",
       "       [0.11401194],\n",
       "       [0.13900847],\n",
       "       [0.11887238],\n",
       "       [0.12859325],\n",
       "       [0.30690182],\n",
       "       [0.19177892],\n",
       "       [0.33481461],\n",
       "       [0.15289543],\n",
       "       [0.1278989 ],\n",
       "       [0.09943063],\n",
       "       [0.13900847],\n",
       "       [0.32648243],\n",
       "       [0.13900847],\n",
       "       [0.16088043],\n",
       "       [0.20358284],\n",
       "       [0.15706152],\n",
       "       [0.13484238],\n",
       "       [0.40286071],\n",
       "       [0.1292876 ],\n",
       "       [0.20636023],\n",
       "       [0.39452854],\n",
       "       [0.19455631],\n",
       "       [0.19039022],\n",
       "       [0.13414803],\n",
       "       [0.10290237],\n",
       "       [0.11540064],\n",
       "       [0.21816414],\n",
       "       [0.07651715],\n",
       "       [0.04457714],\n",
       "       [0.25265519],\n",
       "       [0.20844327],\n",
       "       [0.19594501],\n",
       "       [0.16678239],\n",
       "       [0.25010415],\n",
       "       [0.17580892],\n",
       "       [0.15567282],\n",
       "       [0.14178586],\n",
       "       [0.20962366],\n",
       "       [0.21538675],\n",
       "       [0.06540758],\n",
       "       [0.21531732],\n",
       "       [0.13484238],\n",
       "       [0.17650326],\n",
       "       [0.12512151],\n",
       "       [0.21677545],\n",
       "       [0.26537981],\n",
       "       [0.18761283],\n",
       "       [0.06401889],\n",
       "       [0.15775587],\n",
       "       [0.16525483],\n",
       "       [0.3014859 ],\n",
       "       [0.2001111 ],\n",
       "       [0.10429107],\n",
       "       [0.38411332],\n",
       "       [0.14595195],\n",
       "       [0.22094154],\n",
       "       [0.14109152],\n",
       "       [0.21122066],\n",
       "       [0.2982919 ],\n",
       "       [0.19580614],\n",
       "       [0.13275934],\n",
       "       [0.34870157],\n",
       "       [0.21191501],\n",
       "       [0.15150674],\n",
       "       [0.21260936],\n",
       "       [0.14109152],\n",
       "       [0.13900847],\n",
       "       [0.45146507],\n",
       "       [0.13192612],\n",
       "       [0.14178586],\n",
       "       [0.14511873],\n",
       "       [0.12512151],\n",
       "       [0.23968893],\n",
       "       [0.18761283],\n",
       "       [0.07373976],\n",
       "       [0.16955978],\n",
       "       [0.07578253],\n",
       "       [0.13623108],\n",
       "       [0.33689765],\n",
       "       [0.35009027]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 305)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6433121  0.58823529 0.15335463 ... 0.         1.         0.        ]\n",
      " [0.35031847 0.58823529 0.13738019 ... 0.         1.         0.        ]\n",
      " [0.10100091 0.35294118 0.         ... 0.         1.         0.        ]\n",
      " ...\n",
      " [0.60054595 0.23529412 0.         ... 0.         1.         0.        ]\n",
      " [0.71974522 0.35294118 0.         ... 0.         1.         0.        ]\n",
      " [0.26842584 0.35294118 0.11821086 ... 0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# X_train =X_train.fillna(0)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,activation = 'relu' ,input_shape = (305,)))\n",
    "    model.add(Dense(16,activation = 'relu'))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',loss='binary_crossentropy',metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                9792      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 10,337\n",
      "Trainable params: 10,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =getModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 880 samples, validate on 220 samples\n",
      "Epoch 1/300\n",
      "880/880 [==============================] - 0s 497us/step - loss: 0.5175 - mean_squared_error: 0.0177 - val_loss: 0.4883 - val_mean_squared_error: 0.0067\n",
      "Epoch 2/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4878 - mean_squared_error: 0.0063 - val_loss: 0.4781 - val_mean_squared_error: 0.0031\n",
      "Epoch 3/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4807 - mean_squared_error: 0.0037 - val_loss: 0.4754 - val_mean_squared_error: 0.0023\n",
      "Epoch 4/300\n",
      "880/880 [==============================] - 0s 107us/step - loss: 0.4778 - mean_squared_error: 0.0028 - val_loss: 0.4743 - val_mean_squared_error: 0.0018\n",
      "Epoch 5/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4765 - mean_squared_error: 0.0023 - val_loss: 0.4736 - val_mean_squared_error: 0.0016\n",
      "Epoch 6/300\n",
      "880/880 [==============================] - 0s 89us/step - loss: 0.4756 - mean_squared_error: 0.0020 - val_loss: 0.4733 - val_mean_squared_error: 0.0015\n",
      "Epoch 7/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4752 - mean_squared_error: 0.0019 - val_loss: 0.4733 - val_mean_squared_error: 0.0015\n",
      "Epoch 8/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4745 - mean_squared_error: 0.0016 - val_loss: 0.4730 - val_mean_squared_error: 0.0014\n",
      "Epoch 9/300\n",
      "880/880 [==============================] - 0s 89us/step - loss: 0.4741 - mean_squared_error: 0.0015 - val_loss: 0.4730 - val_mean_squared_error: 0.0014\n",
      "Epoch 10/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4739 - mean_squared_error: 0.0014 - val_loss: 0.4728 - val_mean_squared_error: 0.0013\n",
      "Epoch 11/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4736 - mean_squared_error: 0.0013 - val_loss: 0.4727 - val_mean_squared_error: 0.0013\n",
      "Epoch 12/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4734 - mean_squared_error: 0.0012 - val_loss: 0.4727 - val_mean_squared_error: 0.0013\n",
      "Epoch 13/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4732 - mean_squared_error: 0.0012 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 14/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4730 - mean_squared_error: 0.0011 - val_loss: 0.4726 - val_mean_squared_error: 0.0012\n",
      "Epoch 15/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4729 - mean_squared_error: 0.0010 - val_loss: 0.4729 - val_mean_squared_error: 0.0014\n",
      "Epoch 16/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4729 - mean_squared_error: 0.0010 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 17/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4726 - mean_squared_error: 9.3673e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 18/300\n",
      "880/880 [==============================] - 0s 107us/step - loss: 0.4724 - mean_squared_error: 8.7797e-04 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 19/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4723 - mean_squared_error: 8.3972e-04 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 20/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4722 - mean_squared_error: 7.9143e-04 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 21/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4721 - mean_squared_error: 7.5663e-04 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 22/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4719 - mean_squared_error: 7.1256e-04 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 23/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4718 - mean_squared_error: 6.7683e-04 - val_loss: 0.4723 - val_mean_squared_error: 0.0012\n",
      "Epoch 24/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4718 - mean_squared_error: 6.4364e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 25/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4717 - mean_squared_error: 6.1468e-04 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 26/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4716 - mean_squared_error: 5.8386e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 27/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4715 - mean_squared_error: 5.3487e-04 - val_loss: 0.4724 - val_mean_squared_error: 0.0012\n",
      "Epoch 28/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4714 - mean_squared_error: 5.1066e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 29/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4714 - mean_squared_error: 4.9057e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 30/300\n",
      "880/880 [==============================] - 0s 89us/step - loss: 0.4713 - mean_squared_error: 4.7018e-04 - val_loss: 0.4726 - val_mean_squared_error: 0.0012\n",
      "Epoch 31/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4713 - mean_squared_error: 4.5345e-04 - val_loss: 0.4726 - val_mean_squared_error: 0.0012\n",
      "Epoch 32/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4712 - mean_squared_error: 4.1524e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0013\n",
      "Epoch 33/300\n",
      "880/880 [==============================] - 0s 89us/step - loss: 0.4711 - mean_squared_error: 3.8467e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 34/300\n",
      "880/880 [==============================] - 0s 89us/step - loss: 0.4710 - mean_squared_error: 3.8010e-04 - val_loss: 0.4731 - val_mean_squared_error: 0.0015\n",
      "Epoch 35/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4710 - mean_squared_error: 3.7235e-04 - val_loss: 0.4725 - val_mean_squared_error: 0.0012\n",
      "Epoch 36/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4709 - mean_squared_error: 3.2624e-04 - val_loss: 0.4728 - val_mean_squared_error: 0.0013\n",
      "Epoch 37/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4709 - mean_squared_error: 3.2941e-04 - val_loss: 0.4728 - val_mean_squared_error: 0.0014\n",
      "Epoch 38/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4708 - mean_squared_error: 2.9665e-04 - val_loss: 0.4728 - val_mean_squared_error: 0.0013\n",
      "Epoch 39/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4708 - mean_squared_error: 2.9171e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0015\n",
      "Epoch 40/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4708 - mean_squared_error: 2.9964e-04 - val_loss: 0.4731 - val_mean_squared_error: 0.0014\n",
      "Epoch 41/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4707 - mean_squared_error: 2.7707e-04 - val_loss: 0.4730 - val_mean_squared_error: 0.0014\n",
      "Epoch 42/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4706 - mean_squared_error: 2.4137e-04 - val_loss: 0.4728 - val_mean_squared_error: 0.0013\n",
      "Epoch 43/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4706 - mean_squared_error: 2.3730e-04 - val_loss: 0.4729 - val_mean_squared_error: 0.0014\n",
      "Epoch 44/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4706 - mean_squared_error: 2.2043e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0015\n",
      "Epoch 45/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4705 - mean_squared_error: 2.1354e-04 - val_loss: 0.4728 - val_mean_squared_error: 0.0014\n",
      "Epoch 46/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4705 - mean_squared_error: 1.9182e-04 - val_loss: 0.4729 - val_mean_squared_error: 0.0014\n",
      "Epoch 47/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4705 - mean_squared_error: 2.0480e-04 - val_loss: 0.4729 - val_mean_squared_error: 0.0013\n",
      "Epoch 48/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4705 - mean_squared_error: 2.0329e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0015\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 36us/step - loss: 0.4704 - mean_squared_error: 1.7806e-04 - val_loss: 0.4729 - val_mean_squared_error: 0.0013\n",
      "Epoch 50/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4704 - mean_squared_error: 1.7291e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0014\n",
      "Epoch 51/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4704 - mean_squared_error: 1.7889e-04 - val_loss: 0.4731 - val_mean_squared_error: 0.0014\n",
      "Epoch 52/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4703 - mean_squared_error: 1.4312e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0015\n",
      "Epoch 53/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4703 - mean_squared_error: 1.5680e-04 - val_loss: 0.4731 - val_mean_squared_error: 0.0014\n",
      "Epoch 54/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4703 - mean_squared_error: 1.3712e-04 - val_loss: 0.4731 - val_mean_squared_error: 0.0014\n",
      "Epoch 55/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4702 - mean_squared_error: 1.2472e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0015\n",
      "Epoch 56/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4702 - mean_squared_error: 1.2058e-04 - val_loss: 0.4733 - val_mean_squared_error: 0.0015\n",
      "Epoch 57/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4702 - mean_squared_error: 1.2341e-04 - val_loss: 0.4733 - val_mean_squared_error: 0.0015\n",
      "Epoch 58/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4702 - mean_squared_error: 1.0929e-04 - val_loss: 0.4734 - val_mean_squared_error: 0.0015\n",
      "Epoch 59/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4702 - mean_squared_error: 1.0841e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0014\n",
      "Epoch 60/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4702 - mean_squared_error: 1.0317e-04 - val_loss: 0.4732 - val_mean_squared_error: 0.0014\n",
      "Epoch 61/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4701 - mean_squared_error: 8.9994e-05 - val_loss: 0.4733 - val_mean_squared_error: 0.0014\n",
      "Epoch 62/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4701 - mean_squared_error: 9.2751e-05 - val_loss: 0.4733 - val_mean_squared_error: 0.0015\n",
      "Epoch 63/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4701 - mean_squared_error: 8.6892e-05 - val_loss: 0.4734 - val_mean_squared_error: 0.0015\n",
      "Epoch 64/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4701 - mean_squared_error: 8.1508e-05 - val_loss: 0.4735 - val_mean_squared_error: 0.0015\n",
      "Epoch 65/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4701 - mean_squared_error: 8.1547e-05 - val_loss: 0.4734 - val_mean_squared_error: 0.0014\n",
      "Epoch 66/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4701 - mean_squared_error: 8.3155e-05 - val_loss: 0.4737 - val_mean_squared_error: 0.0016\n",
      "Epoch 67/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4700 - mean_squared_error: 6.8705e-05 - val_loss: 0.4735 - val_mean_squared_error: 0.0015\n",
      "Epoch 68/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4700 - mean_squared_error: 7.0432e-05 - val_loss: 0.4735 - val_mean_squared_error: 0.0015\n",
      "Epoch 69/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4700 - mean_squared_error: 6.1007e-05 - val_loss: 0.4736 - val_mean_squared_error: 0.0015\n",
      "Epoch 70/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4700 - mean_squared_error: 6.2779e-05 - val_loss: 0.4736 - val_mean_squared_error: 0.0015\n",
      "Epoch 71/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4700 - mean_squared_error: 6.1654e-05 - val_loss: 0.4736 - val_mean_squared_error: 0.0016\n",
      "Epoch 72/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4700 - mean_squared_error: 6.9254e-05 - val_loss: 0.4737 - val_mean_squared_error: 0.0016\n",
      "Epoch 73/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4700 - mean_squared_error: 6.6930e-05 - val_loss: 0.4736 - val_mean_squared_error: 0.0015\n",
      "Epoch 74/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4700 - mean_squared_error: 6.6903e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0016\n",
      "Epoch 75/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4700 - mean_squared_error: 5.3321e-05 - val_loss: 0.4737 - val_mean_squared_error: 0.0015\n",
      "Epoch 76/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 4.6376e-05 - val_loss: 0.4737 - val_mean_squared_error: 0.0015\n",
      "Epoch 77/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 4.3715e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0016\n",
      "Epoch 78/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4700 - mean_squared_error: 5.7566e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0016\n",
      "Epoch 79/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4700 - mean_squared_error: 6.4220e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0016\n",
      "Epoch 80/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4700 - mean_squared_error: 6.1896e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0016\n",
      "Epoch 81/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4700 - mean_squared_error: 5.3584e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0016\n",
      "Epoch 82/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4700 - mean_squared_error: 5.8755e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0016\n",
      "Epoch 83/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.2331e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0016\n",
      "Epoch 84/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.3821e-05 - val_loss: 0.4737 - val_mean_squared_error: 0.0015\n",
      "Epoch 85/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.5891e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0016\n",
      "Epoch 86/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.7746e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0016\n",
      "Epoch 87/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.5517e-05 - val_loss: 0.4737 - val_mean_squared_error: 0.0015\n",
      "Epoch 88/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.5239e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0016\n",
      "Epoch 89/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.7749e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0017\n",
      "Epoch 90/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 3.8687e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0016\n",
      "Epoch 91/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.2405e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0017\n",
      "Epoch 92/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 3.6715e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0016\n",
      "Epoch 93/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.0091e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0015\n",
      "Epoch 94/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.9501e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0015\n",
      "Epoch 95/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.1076e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 96/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 5.8428e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 5.9857e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0016\n",
      "Epoch 98/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 5.5519e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 99/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.6113e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0015\n",
      "Epoch 100/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.2142e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 101/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.6835e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0016\n",
      "Epoch 102/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 3.3791e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0015\n",
      "Epoch 103/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.5222e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 104/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.0770e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 105/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.3166e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0016\n",
      "Epoch 106/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.1468e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0016\n",
      "Epoch 107/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.7886e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0015\n",
      "Epoch 108/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.5475e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0016\n",
      "Epoch 109/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.2609e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 110/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.2287e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 111/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.6603e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 112/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.5786e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0016\n",
      "Epoch 113/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.5026e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 114/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.3378e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0016\n",
      "Epoch 115/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.4856e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 116/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.0553e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 117/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.2778e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 118/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.7911e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 119/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.4253e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0016\n",
      "Epoch 120/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.7207e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0014\n",
      "Epoch 121/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4702 - mean_squared_error: 1.5163e-04 - val_loss: 0.4752 - val_mean_squared_error: 0.0020\n",
      "Epoch 122/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4704 - mean_squared_error: 2.0775e-04 - val_loss: 0.4747 - val_mean_squared_error: 0.0018\n",
      "Epoch 123/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4702 - mean_squared_error: 1.5098e-04 - val_loss: 0.4742 - val_mean_squared_error: 0.0016\n",
      "Epoch 124/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4700 - mean_squared_error: 8.1900e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0016\n",
      "Epoch 125/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 5.9047e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0017\n",
      "Epoch 126/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4699 - mean_squared_error: 4.7680e-05 - val_loss: 0.4738 - val_mean_squared_error: 0.0014\n",
      "Epoch 127/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 3.2627e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 128/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4698 - mean_squared_error: 2.1412e-05 - val_loss: 0.4739 - val_mean_squared_error: 0.0015\n",
      "Epoch 129/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.6283e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 130/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.0640e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 131/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.8364e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0016\n",
      "Epoch 132/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4698 - mean_squared_error: 1.8893e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 133/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.4752e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 134/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.9094e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 135/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.0474e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 136/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.9428e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 137/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.7547e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 138/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.7411e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 139/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4698 - mean_squared_error: 2.3904e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 140/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.0968e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 141/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4698 - mean_squared_error: 2.1172e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 142/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.4413e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0014\n",
      "Epoch 143/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.1194e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0016\n",
      "Epoch 144/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 3.0481e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 3.5027e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0017\n",
      "Epoch 146/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 5.1429e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0016\n",
      "Epoch 147/300\n",
      "880/880 [==============================] - 0s 71us/step - loss: 0.4699 - mean_squared_error: 3.2639e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 148/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 4.3677e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0017\n",
      "Epoch 149/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 6.6529e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 150/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.8484e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 151/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 3.3991e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 152/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.4154e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0017\n",
      "Epoch 153/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4700 - mean_squared_error: 7.9268e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0016\n",
      "Epoch 154/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 5.1484e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 155/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.7003e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0015\n",
      "Epoch 156/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.2660e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0014\n",
      "Epoch 157/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.2506e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 158/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.5766e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0017\n",
      "Epoch 159/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 4.4299e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0014\n",
      "Epoch 160/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 3.6778e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0017\n",
      "Epoch 161/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.5024e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0017\n",
      "Epoch 162/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.3441e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 163/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 3.3149e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 164/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 3.0305e-05 - val_loss: 0.4740 - val_mean_squared_error: 0.0014\n",
      "Epoch 165/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.2349e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 166/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.1352e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 167/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.4131e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 168/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.3754e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 169/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.4184e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 170/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.3226e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 171/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.3544e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 172/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.6182e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 173/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.7117e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 174/300\n",
      "880/880 [==============================] - 0s 52us/step - loss: 0.4698 - mean_squared_error: 1.8474e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 175/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 3.0002e-05 - val_loss: 0.4741 - val_mean_squared_error: 0.0014\n",
      "Epoch 176/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.5328e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 177/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.7007e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0016\n",
      "Epoch 178/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.4280e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 179/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.1306e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 180/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 3.7778e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0014\n",
      "Epoch 181/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.7088e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0016\n",
      "Epoch 182/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 3.4014e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 183/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.2689e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 184/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.6646e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 185/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.6196e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 186/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.9051e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 187/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.1437e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 188/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.5658e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 189/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.2315e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 190/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.7940e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 191/300\n",
      "880/880 [==============================] - 0s 38us/step - loss: 0.4698 - mean_squared_error: 1.7861e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 192/300\n",
      "880/880 [==============================] - 0s 30us/step - loss: 0.4699 - mean_squared_error: 4.8845e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 36us/step - loss: 0.4700 - mean_squared_error: 9.5011e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 194/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4701 - mean_squared_error: 1.1542e-04 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 195/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4701 - mean_squared_error: 1.1567e-04 - val_loss: 0.4746 - val_mean_squared_error: 0.0017\n",
      "Epoch 196/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4701 - mean_squared_error: 1.1106e-04 - val_loss: 0.4743 - val_mean_squared_error: 0.0016\n",
      "Epoch 197/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4702 - mean_squared_error: 1.6936e-04 - val_loss: 0.4749 - val_mean_squared_error: 0.0017\n",
      "Epoch 198/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4700 - mean_squared_error: 7.6278e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0017\n",
      "Epoch 199/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.7825e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 200/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 6.0142e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 201/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.5849e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 202/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.8305e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0014\n",
      "Epoch 203/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.0765e-05 - val_loss: 0.4742 - val_mean_squared_error: 0.0015\n",
      "Epoch 204/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.7229e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 205/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.4887e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 206/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 9.6298e-06 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 207/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 7.7430e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 208/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 9.3116e-06 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 209/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 9.1881e-06 - val_loss: 0.4744 - val_mean_squared_error: 0.0016\n",
      "Epoch 210/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 6.9355e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 211/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 4.9208e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 212/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 4.4139e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 213/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.9314e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 214/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 4.4905e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 215/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 7.8022e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 216/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 7.2122e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 217/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 8.0896e-06 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 218/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.2082e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 219/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 9.0643e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 220/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 9.7485e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 221/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.2280e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 222/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.2584e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 223/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.1611e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 224/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.5812e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 225/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.5082e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 226/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.2833e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 227/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.3416e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 228/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.6633e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0014\n",
      "Epoch 229/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.0434e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 230/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.1447e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 231/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.0183e-05 - val_loss: 0.4750 - val_mean_squared_error: 0.0018\n",
      "Epoch 232/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.4795e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 233/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.8371e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 234/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.7570e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 235/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.2724e-05 - val_loss: 0.4748 - val_mean_squared_error: 0.0016\n",
      "Epoch 236/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.2155e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 237/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.6281e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 238/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 3.2682e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 239/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.1153e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 240/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.3890e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.8787e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 242/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.6174e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 243/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 7.0699e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 244/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.5150e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 245/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4700 - mean_squared_error: 7.8561e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 246/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 6.9268e-05 - val_loss: 0.4748 - val_mean_squared_error: 0.0016\n",
      "Epoch 247/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.8953e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 248/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 5.5904e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 249/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.1229e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 250/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 3.9805e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 251/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.9247e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 252/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.1668e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 253/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.6427e-05 - val_loss: 0.4743 - val_mean_squared_error: 0.0015\n",
      "Epoch 254/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.5940e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 255/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.1678e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0016\n",
      "Epoch 256/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.2284e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 257/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 7.2385e-06 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 258/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 9.0919e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 259/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 7.5386e-06 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 260/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 7.2794e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 261/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 6.2380e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 262/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 4.6542e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 263/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 5.8292e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 264/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 4.7717e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 265/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 5.7534e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 266/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 5.8935e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 267/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 7.6370e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 268/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 9.9045e-06 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 269/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.1319e-05 - val_loss: 0.4749 - val_mean_squared_error: 0.0016\n",
      "Epoch 270/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.1785e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 271/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.1674e-05 - val_loss: 0.4748 - val_mean_squared_error: 0.0016\n",
      "Epoch 272/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.3452e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 273/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.6818e-05 - val_loss: 0.4748 - val_mean_squared_error: 0.0016\n",
      "Epoch 274/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.8997e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0015\n",
      "Epoch 275/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.2803e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 276/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.8720e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 277/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.9766e-05 - val_loss: 0.4748 - val_mean_squared_error: 0.0016\n",
      "Epoch 278/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 5.8341e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 279/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.4839e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 280/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4699 - mean_squared_error: 4.9763e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 281/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.7690e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 282/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.2915e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 283/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 2.0940e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 284/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 1.5724e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 285/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.0369e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 286/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 8.9815e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 287/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 7.9997e-06 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 288/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 7.0043e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0016\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.0182e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 290/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 8.9487e-06 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 291/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4698 - mean_squared_error: 1.5165e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n",
      "Epoch 292/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.3423e-05 - val_loss: 0.4748 - val_mean_squared_error: 0.0016\n",
      "Epoch 293/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 1.6136e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 294/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 2.8751e-05 - val_loss: 0.4748 - val_mean_squared_error: 0.0016\n",
      "Epoch 295/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.2126e-05 - val_loss: 0.4744 - val_mean_squared_error: 0.0015\n",
      "Epoch 296/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4699 - mean_squared_error: 4.5609e-05 - val_loss: 0.4751 - val_mean_squared_error: 0.0017\n",
      "Epoch 297/300\n",
      "880/880 [==============================] - 0s 35us/step - loss: 0.4699 - mean_squared_error: 4.4281e-05 - val_loss: 0.4746 - val_mean_squared_error: 0.0015\n",
      "Epoch 298/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.1784e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0015\n",
      "Epoch 299/300\n",
      "880/880 [==============================] - 0s 36us/step - loss: 0.4698 - mean_squared_error: 3.5414e-05 - val_loss: 0.4747 - val_mean_squared_error: 0.0016\n",
      "Epoch 300/300\n",
      "880/880 [==============================] - 0s 53us/step - loss: 0.4698 - mean_squared_error: 2.7812e-05 - val_loss: 0.4745 - val_mean_squared_error: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2508d4766c8>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = model.fit(X_train,Y_train,epochs=300,validation_data=(X_test,Y_test),shuffle=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(XTest)\n",
    "# test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "mans = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = Scalar.inverse_transform(mans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73810.09 ]\n",
      " [114931.9  ]\n",
      " [118173.21 ]\n",
      " [152990.27 ]\n",
      " [113105.9  ]\n",
      " [326761.2  ]\n",
      " [194175.58 ]\n",
      " [313434.88 ]\n",
      " [150978.97 ]\n",
      " [328974.12 ]\n",
      " [187441.08 ]\n",
      " [190529.75 ]\n",
      " [119861.5  ]\n",
      " [138806.23 ]\n",
      " [118182.266]\n",
      " [289746.97 ]\n",
      " [207723.73 ]\n",
      " [125786.7  ]\n",
      " [166495.45 ]\n",
      " [129426.85 ]\n",
      " [132449.95 ]\n",
      " [234439.33 ]\n",
      " [107631.99 ]\n",
      " [106998.16 ]\n",
      " [175347.61 ]\n",
      " [114201.74 ]\n",
      " [189950.1  ]\n",
      " [214500.66 ]\n",
      " [236102.5  ]\n",
      " [132772.36 ]\n",
      " [175631.66 ]\n",
      " [117634.14 ]\n",
      " [148126.55 ]\n",
      " [212833.81 ]\n",
      " [155663.89 ]\n",
      " [ 93437.7  ]\n",
      " [103454.21 ]\n",
      " [ 82092.125]\n",
      " [193884.62 ]\n",
      " [135849.64 ]\n",
      " [111478.28 ]\n",
      " [186315.88 ]\n",
      " [411793.4  ]\n",
      " [ 80163.37 ]\n",
      " [102823.734]\n",
      " [116011.695]\n",
      " [155573.64 ]\n",
      " [181763.06 ]\n",
      " [100843.37 ]\n",
      " [132129.97 ]\n",
      " [143254.66 ]\n",
      " [160477.1  ]\n",
      " [206868.69 ]\n",
      " [120657.16 ]\n",
      " [233659.6  ]\n",
      " [208111.48 ]\n",
      " [206388.34 ]\n",
      " [192522.66 ]\n",
      " [249303.03 ]\n",
      " [203739.16 ]\n",
      " [135002.73 ]\n",
      " [192579.44 ]\n",
      " [131781.38 ]\n",
      " [175047.94 ]\n",
      " [256429.28 ]\n",
      " [246348.42 ]\n",
      " [222486.83 ]\n",
      " [178960.83 ]\n",
      " [241276.31 ]\n",
      " [596741.6  ]\n",
      " [137330.34 ]\n",
      " [152535.45 ]\n",
      " [163272.73 ]\n",
      " [163291.67 ]\n",
      " [227256.77 ]\n",
      " [288549.9  ]\n",
      " [132511.97 ]\n",
      " [101459.12 ]\n",
      " [160718.05 ]\n",
      " [ 68335.52 ]\n",
      " [148921.33 ]\n",
      " [369432.9  ]\n",
      " [453482.38 ]\n",
      " [157495.55 ]\n",
      " [210339.03 ]\n",
      " [131685.27 ]\n",
      " [134476.08 ]\n",
      " [220914.84 ]\n",
      " [187667.36 ]\n",
      " [171248.88 ]\n",
      " [210706.38 ]\n",
      " [157752.34 ]\n",
      " [141559.72 ]\n",
      " [147544.03 ]\n",
      " [165523.48 ]\n",
      " [179074.38 ]\n",
      " [253090.5  ]\n",
      " [203779.34 ]\n",
      " [158253.48 ]\n",
      " [125620.36 ]\n",
      " [102616.53 ]\n",
      " [209473.05 ]\n",
      " [145863.77 ]\n",
      " [179853.17 ]\n",
      " [145695.64 ]\n",
      " [222220.89 ]\n",
      " [ 92839.984]\n",
      " [200445.   ]\n",
      " [137330.34 ]\n",
      " [285606.8  ]\n",
      " [212608.34 ]\n",
      " [191232.44 ]\n",
      " [ 75658.54 ]\n",
      " [131712.39 ]\n",
      " [122686.71 ]\n",
      " [108707.37 ]\n",
      " [125018.836]\n",
      " [263230.4  ]\n",
      " [ 39441.76 ]\n",
      " [ 72776.36 ]\n",
      " [ 93889.97 ]\n",
      " [130307.664]\n",
      " [163571.95 ]\n",
      " [100088.41 ]\n",
      " [212316.92 ]\n",
      " [125553.766]\n",
      " [254194.3  ]\n",
      " [164441.73 ]\n",
      " [315616.2  ]\n",
      " [131027.22 ]\n",
      " [256293.22 ]\n",
      " [115352.336]\n",
      " [121784.24 ]\n",
      " [135306.53 ]\n",
      " [ 49961.99 ]\n",
      " [153447.55 ]\n",
      " [165833.62 ]\n",
      " [210118.11 ]\n",
      " [132124.5  ]\n",
      " [222428.94 ]\n",
      " [200211.   ]\n",
      " [290348.94 ]\n",
      " [186016.86 ]\n",
      " [431884.6  ]\n",
      " [238093.94 ]\n",
      " [198886.75 ]\n",
      " [214293.95 ]\n",
      " [147285.02 ]\n",
      " [125291.71 ]\n",
      " [112589.086]\n",
      " [208217.   ]\n",
      " [173628.5  ]\n",
      " [ 96336.52 ]\n",
      " [288530.75 ]\n",
      " [204329.2  ]\n",
      " [112550.95 ]\n",
      " [331150.94 ]\n",
      " [ 88815.38 ]\n",
      " [209708.58 ]\n",
      " [143935.83 ]\n",
      " [206685.7  ]\n",
      " [112466.63 ]\n",
      " [175819.03 ]\n",
      " [131510.42 ]\n",
      " [171983.66 ]\n",
      " [204564.14 ]\n",
      " [120985.734]\n",
      " [266541.66 ]\n",
      " [343342.3  ]\n",
      " [159298.22 ]\n",
      " [171719.73 ]\n",
      " [141095.98 ]\n",
      " [135511.06 ]\n",
      " [162998.03 ]\n",
      " [181815.67 ]\n",
      " [162278.1  ]\n",
      " [167621.75 ]\n",
      " [176689.5  ]\n",
      " [233797.16 ]\n",
      " [ 45663.824]\n",
      " [194909.95 ]\n",
      " [156882.89 ]\n",
      " [148168.4  ]\n",
      " [132685.83 ]\n",
      " [201639.38 ]\n",
      " [148413.11 ]\n",
      " [169775.66 ]\n",
      " [190103.67 ]\n",
      " [253471.31 ]\n",
      " [336156.47 ]\n",
      " [151891.14 ]\n",
      " [107316.84 ]\n",
      " [163955.92 ]\n",
      " [178924.75 ]\n",
      " [103341.24 ]\n",
      " [130851.71 ]\n",
      " [131982.98 ]\n",
      " [151735.53 ]\n",
      " [626495.75 ]\n",
      " [147881.5  ]\n",
      " [221519.39 ]\n",
      " [171382.34 ]\n",
      " [312701.66 ]\n",
      " [231801.06 ]\n",
      " [133759.48 ]\n",
      " [309318.56 ]\n",
      " [208034.97 ]\n",
      " [138958.89 ]\n",
      " [154899.83 ]\n",
      " [146511.55 ]\n",
      " [285839.75 ]\n",
      " [196656.56 ]\n",
      " [357521.2  ]\n",
      " [346995.06 ]\n",
      " [ 97383.2  ]\n",
      " [185576.2  ]\n",
      " [278272.03 ]\n",
      " [209622.94 ]\n",
      " [269377.88 ]\n",
      " [ 92210.29 ]\n",
      " [159697.58 ]\n",
      " [ 92429.1  ]\n",
      " [221620.52 ]\n",
      " [ 95059.984]\n",
      " [294127.72 ]\n",
      " [ 48341.73 ]\n",
      " [118937.836]\n",
      " [135181.19 ]\n",
      " [222667.75 ]\n",
      " [181232.44 ]\n",
      " [276735.12 ]\n",
      " [117114.32 ]\n",
      " [123554.04 ]\n",
      " [162529.31 ]\n",
      " [106279.29 ]\n",
      " [177584.92 ]\n",
      " [150303.52 ]\n",
      " [ 79480.15 ]\n",
      " [220366.61 ]\n",
      " [121768.086]\n",
      " [107558.88 ]\n",
      " [160935.11 ]\n",
      " [213748.36 ]\n",
      " [160334.17 ]\n",
      " [215728.95 ]\n",
      " [ 85328.195]\n",
      " [274241.   ]\n",
      " [331499.44 ]\n",
      " [191499.61 ]\n",
      " [109198.734]\n",
      " [214248.78 ]\n",
      " [165403.12 ]\n",
      " [118549.24 ]\n",
      " [416518.3  ]\n",
      " [218066.12 ]\n",
      " [206894.88 ]\n",
      " [103771.914]\n",
      " [164884.6  ]\n",
      " [172052.1  ]\n",
      " [296339.53 ]\n",
      " [209590.38 ]\n",
      " [226361.   ]\n",
      " [147837.52 ]\n",
      " [184566.77 ]\n",
      " [134689.45 ]\n",
      " [220961.75 ]\n",
      " [194988.89 ]\n",
      " [116658.734]\n",
      " [140582.03 ]\n",
      " [226223.86 ]\n",
      " [125012.62 ]\n",
      " [172088.72 ]\n",
      " [241814.17 ]\n",
      " [521443.94 ]\n",
      " [240588.81 ]\n",
      " [271477.5  ]\n",
      " [116539.086]\n",
      " [120849.68 ]\n",
      " [ 98914.42 ]\n",
      " [180811.69 ]\n",
      " [103692.63 ]\n",
      " [182154.86 ]\n",
      " [143845.5  ]\n",
      " [168566.33 ]\n",
      " [ 99344.34 ]\n",
      " [144173.92 ]\n",
      " [358277.97 ]\n",
      " [145477.75 ]\n",
      " [352872.1  ]\n",
      " [125002.375]\n",
      " [198259.7  ]\n",
      " [129836.75 ]\n",
      " [117646.586]\n",
      " [158800.48 ]\n",
      " [207938.23 ]\n",
      " [297601.78 ]\n",
      " [156328.69 ]\n",
      " [135591.83 ]\n",
      " [145808.22 ]\n",
      " [162266.97 ]\n",
      " [115190.14 ]\n",
      " [183574.03 ]\n",
      " [198010.25 ]\n",
      " [291603.7  ]\n",
      " [114051.95 ]\n",
      " [297085.44 ]\n",
      " [137774.64 ]\n",
      " [116918.28 ]\n",
      " [109812.59 ]\n",
      " [174532.31 ]\n",
      " [193813.6  ]\n",
      " [156538.48 ]\n",
      " [ 83596.69 ]\n",
      " [251293.03 ]\n",
      " [177213.6  ]\n",
      " [191309.73 ]\n",
      " [135816.98 ]\n",
      " [302852.25 ]\n",
      " [121905.71 ]\n",
      " [204877.95 ]\n",
      " [178603.92 ]\n",
      " [132955.03 ]\n",
      " [140731.45 ]\n",
      " [180659.47 ]\n",
      " [138517.52 ]\n",
      " [148363.27 ]\n",
      " [266571.47 ]\n",
      " [139770.14 ]\n",
      " [114730.41 ]\n",
      " [184974.52 ]\n",
      " [208932.56 ]\n",
      " [123209.15 ]\n",
      " [132653.84 ]\n",
      " [193661.02 ]\n",
      " [149882.48 ]\n",
      " [150651.44 ]\n",
      " [121640.67 ]\n",
      " [358233.62 ]\n",
      " [138243.8  ]\n",
      " [171435.28 ]\n",
      " [271297.75 ]\n",
      " [144095.4  ]\n",
      " [357706.2  ]\n",
      " [100448.37 ]\n",
      " [202286.86 ]\n",
      " [118641.164]\n",
      " [148737.05 ]\n",
      " [224024.06 ]\n",
      " [ 79352.63 ]\n",
      " [ 67626.016]\n",
      " [128515.19 ]\n",
      " [285242.53 ]\n",
      " [136067.86 ]\n",
      " [ 94390.65 ]\n",
      " [171797.8  ]\n",
      " [166105.81 ]\n",
      " [223347.88 ]\n",
      " [289173.44 ]\n",
      " [144557.69 ]\n",
      " [131324.02 ]]\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred=pd.DataFrame(ans,columns=['SalePrice'])\n",
    "Y_Pred.to_csv('Y_prednew.csv',index=True,index_label =['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred.to_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
